{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que tu archivo CSV se llama 'libros.csv'\n",
    "df = pd.read_csv('C:\\\\Users\\\\Fukushima\\\\Documents\\\\GitHub\\\\ProyectoFinalVV\\\\data\\\\raw\\\\librosyafiltrados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'pagesNumber', 'RatingDist4', 'RatingDistTotal', 'Authors',\n",
       "       'Rating', 'RatingDist5', 'RatingDist3', 'is_collection',\n",
       "       'book_category', 'Name_encoded', 'Authors_encoded',\n",
       "       'RatingDistTotal_numeric'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LA diferencia entre este código y el anterior es que en este modelo estoy restringiendo mucho más las varaibles para así poder dar una recomendación más exacta ya que el modelo anterior me proporcionaba recomendaciones similares en libros más populares como en Harry Potter o en el conde de MonteCristo. El modelo actual es mucho más preciso, a pesar de que en Harry Potter me sigue recomendando libros de la misma saga, al menos ya no son los mismos pero en diferentes idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060441, 362084)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "features = df[['Rating', 'pagesNumber', 'Authors']]\n",
    "\n",
    "# Normalizar las columnas numéricas (Rating y pagesNumber)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features[['Rating', 'pagesNumber']])\n",
    "\n",
    "# Realizar one-hot encoding para la columna 'Authors'\n",
    "encoder = OneHotEncoder()\n",
    "authors_encoded = encoder.fit_transform(features[['Authors']])\n",
    "\n",
    "# Combinar las características escaladas y el encoding de autores en una matriz dispersa\n",
    "matrix_features = hstack([features_scaled, authors_encoded])\n",
    "\n",
    "# Asegurarse de que matrix_features sea una matriz bidimensional\n",
    "print(matrix_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Seleccionar columnas numéricas relevantes\n",
    "numerical_columns = ['pagesNumber', 'Rating', 'RatingDistTotal_numeric']  \n",
    "\n",
    "if all(col in df.columns for col in numerical_columns):\n",
    "    numerical_features = df[numerical_columns].fillna(0).values  # Asegurarse de que no haya NaNs\n",
    "    \n",
    "    # Escalar los valores numéricos para evitar que un rango domine a los otros\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features = scaler.fit_transform(numerical_features)\n",
    "else:\n",
    "    print(\"Algunas columnas numéricas faltan en el DataFrame.\")\n",
    "    numerical_features = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Lista de palabras clave para detectar versiones alternativas\n",
    "keywords = [\"guide\", \"version\", \"edition\", \"abridged\", \"unabridged\", \"adaptation\", \"annotated\", \"bloom's\", \"summary\"]\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def has_common_keywords(title1, title2):\n",
    "    title1 = title1.lower()\n",
    "    title2 = title2.lower()\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if keyword in title1 and keyword in title2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_title_similarity(input_title, all_titles):\n",
    "    similarities = [similar(input_title, title) for title in all_titles]\n",
    "    return np.array(similarities)\n",
    "\n",
    "def get_book_recommendations(input_book, num_recommendations=20):\n",
    "    try:\n",
    "        idx = df[df['Name'] == input_book].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"Libro '{input_book}' no encontrado en el DataFrame.\")\n",
    "        return pd.DataFrame(), []\n",
    "    \n",
    "    input_title = df['Name'].iloc[idx]\n",
    "    title_similarities = get_title_similarity(input_title, df['Name'].values)\n",
    "    \n",
    "    input_features = numerical_features[idx].reshape(1, -1)\n",
    "    numerical_similarities = cosine_similarity(input_features, numerical_features)[0]\n",
    "\n",
    "    total_similarity = (0.7 * title_similarities) + (0.3 * numerical_similarities)\n",
    "    \n",
    "    sim_scores = list(enumerate(total_similarity))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:]  # Excluir el libro de entrada\n",
    "\n",
    "    filtered_scores = []\n",
    "    for i, score in sim_scores:\n",
    "        candidate_title = df['Name'].iloc[i]\n",
    "        base_title = candidate_title.split(\":\")[0].strip().lower()\n",
    "        if similar(base_title, input_title.lower()) < 0.8 and not has_common_keywords(input_title, candidate_title):\n",
    "            if score < 0.7:  # Filtrar por umbral de similitud específico\n",
    "                filtered_scores.append((i, score))\n",
    "                if len(filtered_scores) == num_recommendations:\n",
    "                    break\n",
    "    \n",
    "    book_indices = [i[0] for i in filtered_scores]\n",
    "    recommendations = df[['Name', 'Authors']].iloc[book_indices]\n",
    "    return recommendations, filtered_scores\n",
    "\n",
    "def remove_duplicate_titles_global(recommendations):\n",
    "    seen_titles = set()\n",
    "    unique_recommendations = []\n",
    "    scores_dict = {}\n",
    "    \n",
    "    for _, row in recommendations.iterrows():\n",
    "        title = row['Name']\n",
    "        base_title = title.split(\":\")[0].strip().lower()\n",
    "        if base_title not in seen_titles:\n",
    "            seen_titles.add(base_title)\n",
    "            unique_recommendations.append(row)\n",
    "            # Save the highest similarity score for each unique title\n",
    "            index = recommendations.index.get_loc(row.name)\n",
    "            scores_dict[base_title] = scores[index][1]\n",
    "    \n",
    "    # Convert the list to DataFrame\n",
    "    unique_recommendations_df = pd.DataFrame(unique_recommendations)\n",
    "    return unique_recommendations_df, scores_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'Harry Potter and the Prisoner of Azkaban':\n",
      "- Book: Harry Potter and the Chamber of Secrets (Harry Potter, #2), Author: J.K. Rowling, Similarity Score: 0.7000\n",
      "- Book: Harri Potter maen yr Athronydd, Author: J.K. Rowling, Similarity Score: 0.6999\n",
      "- Book: Harry Potter und die Heiligtümer des Todes, Author: J.K. Rowling, Similarity Score: 0.6927\n",
      "- Book: Harry Potter e la Pietra Filosofale, Author: J.K. Rowling, Similarity Score: 0.6919\n",
      "- Book: Harry Potter and the Deathly Hallows (Harry Potter, #7), Author: J.K. Rowling, Similarity Score: 0.6832\n"
     ]
    }
   ],
   "source": [
    "input_book = \"Harry Potter and the Prisoner of Azkaban\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'The Hound of the Baskervilles':\n",
      "- Book: The Wind In The Willows, Author: Kenneth Grahame, Similarity Score: 0.7000\n",
      "- Book: The Name of the Rose, Author: Umberto Eco, Similarity Score: 0.6996\n",
      "- Book: The Day of the Jackal, Author: Frederick Forsyth, Similarity Score: 0.6992\n",
      "- Book: The Gift of the Magi, Author: O. Henry, Similarity Score: 0.6978\n",
      "- Book: The Hunchback of Notre Dame, Author: Victor Hugo, Similarity Score: 0.6971\n"
     ]
    }
   ],
   "source": [
    "input_book = \"The Hound of the Baskervilles\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'The Count of Monte Cristo':\n",
      "- Book: The Call of the Wild, Author: Jack London, Similarity Score: 0.6984\n",
      "- Book: The tale of Peter Rabbit, Author: Beatrix Potter, Similarity Score: 0.6984\n",
      "- Book: The House Of The Spirits, Author: Isabel Allende, Similarity Score: 0.6961\n",
      "- Book: The Phantom of the Opera, Author: Gaston Leroux, Similarity Score: 0.6954\n"
     ]
    }
   ],
   "source": [
    "input_book = \"The Count of Monte Cristo\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'The Catcher in the Rye':\n",
      "- Book: The Devil in the White City, Author: Erik Larson, Similarity Score: 0.7000\n",
      "- Book: The Power and the Glory, Author: Graham Greene, Similarity Score: 0.6987\n",
      "- Book: The Call of the Wild, Author: Jack London, Similarity Score: 0.6982\n",
      "- Book: The Phantom of the Opera, Author: Gaston Leroux, Similarity Score: 0.6946\n"
     ]
    }
   ],
   "source": [
    "input_book = \"The Catcher in the Rye\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'The Hobbit':\n",
      "- Book: The Witches, Author: Roald Dahl, Similarity Score: 0.6990\n",
      "- Book: The Prophet, Author: Kahlil Gibran, Similarity Score: 0.6965\n",
      "- Book: Bilbo le hobbit, Author: J.R.R. Tolkien, Similarity Score: 0.6920\n",
      "- Book: The Help, Author: Kathryn Stockett, Similarity Score: 0.6888\n",
      "- Book: The Firm, Author: Robin Waterfield, Similarity Score: 0.6887\n",
      "- Book: The Road, Author: Cormac McCarthy, Similarity Score: 0.6885\n"
     ]
    }
   ],
   "source": [
    "input_book = \"The Hobbit\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for '1984':\n",
      "- Book: Animal Farm / 1984, Author: George Orwell, Similarity Score: 0.5365\n",
      "- Book: 1974, Author: David Peace, Similarity Score: 0.5171\n",
      "- Book: 1945, Author: Newt Gingrich, Similarity Score: 0.5078\n",
      "- Book: 1934, Author: Alberto Moravia, Similarity Score: 0.5047\n",
      "- Book: 1988, Author: Andrew McGahan, Similarity Score: 0.5026\n",
      "- Book: Fever 1793, Author: Laurie Halse Anderson, Similarity Score: 0.4833\n",
      "- Book: 1942, Author: Robert Conroy, Similarity Score: 0.4833\n",
      "- Book: 1776, Author: David McCullough, Similarity Score: 0.4749\n",
      "- Book: 1968, Author: Ed Sanders, Similarity Score: 0.4724\n",
      "- Book: Fiebre 1793, Author: Laurie Halse Anderson, Similarity Score: 0.4698\n"
     ]
    }
   ],
   "source": [
    "input_book = \"1984\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book recommendations for 'Pride and Prejudice':\n",
      "- Book: Le Poids De La Preuve, Author: Scott Turow, Similarity Score: 0.6989\n",
      "- Book: War And Peace, Author: Leo Tolstoy, Similarity Score: 0.6932\n",
      "- Book: Wall and Piece, Author: Banksy, Similarity Score: 0.6711\n",
      "- Book: Orgullo y Prejuicio, Author: Jane Austen, Similarity Score: 0.6684\n",
      "- Book: Crime and Punishment, Author: Fyodor Dostoyevsky, Similarity Score: 0.6586\n",
      "- Book: Prince and the Pauper, Author: Mark Twain, Similarity Score: 0.6541\n",
      "- Book: El Principe / the Prince, Author: Niccolò Machiavelli, Similarity Score: 0.6495\n",
      "- Book: Rue de La Sardine, Author: John Steinbeck, Similarity Score: 0.6495\n"
     ]
    }
   ],
   "source": [
    "input_book = \"Pride and Prejudice\"\n",
    "recommendations, scores = get_book_recommendations(input_book)\n",
    "\n",
    "# Filtrar duplicados globalmente\n",
    "unique_recommendations, scores_dict = remove_duplicate_titles_global(recommendations)\n",
    "\n",
    "print(\"Book recommendations for '{}':\".format(input_book))\n",
    "for _, row in unique_recommendations.iterrows():\n",
    "    base_title = row['Name'].split(\":\")[0].strip().lower()\n",
    "    print(\"- Book: {}, Author: {}, Similarity Score: {:.4f}\".format(row['Name'], row['Authors'], scores_dict.get(base_title, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\Fukushima\\\\Documents\\\\GitHub\\\\ProyectoFinalVV\\\\data\\\\raw\\\\librosyafiltrados.csv')\n",
    "\n",
    "# Definir X y y\n",
    "X = df[['Name_encoded', 'Authors_encoded', 'pagesNumber', 'RatingDistTotal_numeric']]\n",
    "y = df['Rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.05183820679448788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modelo_libros_entrenado.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = modelo.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(modelo, 'modelo_libros_entrenado.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.05183820679448788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que 'y_pred' son las predicciones de tu modelo y 'y_test' son los valores reales\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrica de accuracy se usa generalmente para problemas de clasificación, no para problemas de regresión. Dado que estás trabajando con un modelo de regresión lineal, Rating es una variable continua, no una categórica. Por lo tanto, no puedo usar accuracy para evaluar mi modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.05183820679448788\n",
      "MAE: 0.013889439572962027\n",
      "MSE: 0.0026871996836680895\n",
      "R²: 0.9819942434252295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calcular las métricas\n",
    "y_pred = modelo.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE (Root Mean Square Error): 0.0518 El error promedio en la misma escala que la variable objetivo es bajo, indicando que las predicciones están cerca de los valores reales.\n",
    "\n",
    "- MAE (Mean Absolute Error): 0.0139 El error absoluto promedio es también bajo, sugiriendo que en promedio, las predicciones están muy cerca de los valores reales.\n",
    "\n",
    "- MSE (Mean Squared Error): 0.0027 El error cuadrático medio es pequeño, lo que indica que el modelo está haciendo buenas predicciones sin grandes errores.\n",
    "\n",
    "- R² (Coeficiente de Determinación): 0.982 Un R² cercano a 1 significa que el modelo explica casi el 98.2% de la variación en la variable objetivo, lo que es excelente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
